import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import numpy as np
import matplotlib.pyplot as plt
import random

# For XAI Libraries
from captum.attr import GradCam, IntegratedGradients
import shap # For model-agnostic explanations

# --- Configuration & Global Variables ---
IMG_SIZE = 32 # Size of our dummy images (e.g., 32x32 pixels)
NUM_CLASSES = 2 # Binary classification: e.g., "circle" or "square"
NUM_TRAIN_SAMPLES = 1000
NUM_TEST_SAMPLES = 200

# Set device for PyTorch (GPU if available, else CPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# --- Section 1: Black-Box Model Definition (PyTorch CNN) ---
# This is our "black-box" model that we want to explain.
# It's a simple CNN for image classification.

class SimpleCNN(nn.Module):
    """
    A simple Convolutional Neural Network (CNN) for binary image classification.
    This will serve as our 'black-box' model for XAI demonstrations.
    """
    def __init__(self, num_classes=NUM_CLASSES):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1) # Input 1 channel (grayscale)
        self.pool1 = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)
        self.pool2 = nn.MaxPool2d(2, 2)
        
        # Calculate input features for the first fully connected layer
        # (IMG_SIZE / 2 / 2) = IMG_SIZE / 4 for final dimension
        self.fc1_input_features = 32 * (IMG_SIZE // 4) * (IMG_SIZE // 4)
        
        self.fc1 = nn.Linear(self.fc1_input_features, 128)
        self.fc2 = nn.Linear(128, num_classes)

    def forward(self, x):
        x = self.pool1(F.relu(self.conv1(x)))
        x = self.pool2(F.relu(self.conv2(x)))
        x = x.view(-1, self.fc1_input_features) # Flatten for fully connected layers
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# --- Section 2: Dummy Dataset Generation ---
# We'll create a simple dataset of circles (class 0) and squares (class 1).

class DummyShapesDataset(Dataset):
    """
    Generates a dataset of simple black & white images containing either a circle or a square.
    """
    def __init__(self, num_samples, img_size, num_classes):
        self.num_samples = num_samples
        self.img_size = img_size
        self.num_classes = num_classes
        self.data = []

        print(f"Generating {num_samples} dummy images (size {img_size}x{img_size})...")
        for _ in range(num_samples):
            img = np.zeros((img_size, img_size), dtype=np.float32) # Black background
            
            # Randomly decide shape
            shape_type = random.randint(0, num_classes - 1) # 0 for circle, 1 for square
            label = shape_type

            if shape_type == 0: # Circle
                center_x, center_y = random.randint(img_size // 4, img_size * 3 // 4), random.randint(img_size // 4, img_size * 3 // 4)
                radius = random.randint(img_size // 8, img_size // 4)
                for x in range(img_size):
                    for y in range(img_size):
                        if (x - center_x)**2 + (y - center_y)**2 < radius**2:
                            img[y, x] = 1.0 # White circle
            else: # Square
                size = random.randint(img_size // 4, img_size // 2)
                top_left_x = random.randint(0, img_size - size)
                top_left_y = random.randint(0, img_size - size)
                img[top_left_y : top_left_y + size, top_left_x : top_left_x + size] = 1.0 # White square
            
            self.data.append((torch.from_numpy(img).unsqueeze(0), torch.tensor(label, dtype=torch.long)))

        print("Dummy data generation complete.")

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        return self.data[idx]

# Create dummy datasets
train_dataset = DummyShapesDataset(NUM_TRAIN_SAMPLES, IMG_SIZE, NUM_CLASSES)
test_dataset = DummyShapesDataset(NUM_TEST_SAMPLES, IMG_SIZE, NUM_CLASSES)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

print(f"Train dataset size: {len(train_dataset)}")
print(f"Test dataset size: {len(test_dataset)}")


# --- Section 3: Model Training ---
# Train the simple CNN on the dummy dataset.

def train_model(model, train_loader, test_loader, epochs=10):
    """
    Trains the CNN model and evaluates its performance.
    """
    print("\n--- Starting Model Training ---")
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    for epoch in range(epochs):
        model.train() # Set model to training mode
        running_loss = 0.0
        correct_predictions = 0
        total_predictions = 0

        for i, (inputs, labels) in enumerate(train_loader):
            inputs, labels = inputs.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total_predictions += labels.size(0)
            correct_predictions += (predicted == labels).sum().item()
        
        train_accuracy = correct_predictions / total_predictions

        # Validation
        model.eval() # Set model to evaluation mode
        val_loss = 0.0
        correct_val_predictions = 0
        total_val_predictions = 0
        with torch.no_grad():
            for inputs, labels in test_loader:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                val_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                total_val_predictions += labels.size(0)
                correct_val_predictions += (predicted == labels).sum().item()
        
        val_accuracy = correct_val_predictions / total_val_predictions

        print(f"Epoch {epoch+1}/{epochs}, Train Loss: {running_loss/len(train_loader):.4f}, Train Acc: {train_accuracy:.4f} | Val Loss: {val_loss/len(test_loader):.4f}, Val Acc: {val_accuracy:.4f}")
    
    print("--- Model Training Finished ---")

# Instantiate and train the model
model = SimpleCNN(num_classes=NUM_CLASSES).to(device)
train_model(model, train_loader, test_loader, epochs=15) # Train for a few epochs

# --- Section 4: Grad-CAM Implementation (using Captum) ---
# Grad-CAM provides a visual explanation of where the model "looks" in the image
# to make a particular classification decision.

def visualize_grad_cam(model, test_loader, num_samples=3):
    """
    Visualizes Grad-CAM heatmaps for a few test samples.
    """
    print("\n--- Visualizing Grad-CAM Explanations ---")
    model.eval()

    # Define the target layer for Grad-CAM.
    # Typically, this is the last convolutional layer before pooling/flattening.
    # For SimpleCNN, `model.conv2` is a good candidate.
    target_layer = model.conv2 
    gc = GradCam(model, target_layer)

    fig, axes = plt.subplots(num_samples, 3, figsize=(10, num_samples * 4))
    fig.suptitle('Grad-CAM Explanations', fontsize=16)

    samples_processed = 0
    with torch.no_grad():
        for inputs, labels in test_loader:
            if samples_processed >= num_samples:
                break
            
            # Select one sample from the batch
            input_img = inputs[0].unsqueeze(0).to(device) # Add batch dim
            true_label = labels[0].item()

            # Predict with the model
            logits = model(input_img)
            probabilities = F.softmax(logits, dim=1)
            predicted_label = torch.argmax(probabilities).item()
            predicted_confidence = probabilities[0, predicted_label].item()

            # Compute Grad-CAM attributions for the predicted class
            # `target` specifies the class for which to compute attributions
            attributions_gc = gc.attribute(input_img, target=predicted_label)
            
            # Convert attributions to numpy and squeeze channel dimension
            attribution_heatmap = attributions_gc.squeeze().cpu().numpy()

            # Original image (remove channel and batch dimensions)
            original_img_np = input_img.squeeze().cpu().numpy()

            # Plotting
            ax = axes[samples_processed, 0]
            ax.imshow(original_img_np, cmap='gray')
            ax.set_title(f'Original (True: {true_label})')
            ax.axis('off')

            ax = axes[samples_processed, 1]
            # Overlay heatmap (usually needs to be resized to original image dimensions)
            ax.imshow(original_img_np, cmap='gray')
            ax.imshow(attribution_heatmap, cmap='jet', alpha=0.5, extent=(0, IMG_SIZE, 0, IMG_SIZE))
            ax.set_title(f'Grad-CAM (Pred: {predicted_label}, Conf: {predicted_confidence:.2f})')
            ax.axis('off')
            
            # Create a combined image with original and heatmap side-by-side or overlaid for saving
            # This is illustrative, the plot above already overlays.
            ax = axes[samples_processed, 2]
            ax.imshow(attribution_heatmap, cmap='jet') # Just the heatmap
            ax.set_title('Heatmap')
            ax.axis('off')

            samples_processed += 1
    
    plt.tight_layout()
    plt.show()
    print("--- Grad-CAM Explanation Complete ---")


# --- Section 5: Integrated Gradients Implementation (using Captum) ---
# Integrated Gradients attributes the prediction to input features (pixels),
# showing which pixels contribute positively or negatively to the prediction.

def visualize_integrated_gradients(model, test_loader, num_samples=3):
    """
    Visualizes Integrated Gradients attributions for a few test samples.
    """
    print("\n--- Visualizing Integrated Gradients Explanations ---")
    model.eval()

    # Integrated Gradients
    ig = IntegratedGradients(model)

    fig, axes = plt.subplots(num_samples, 2, figsize=(8, num_samples * 4))
    fig.suptitle('Integrated Gradients Explanations', fontsize=16)

    samples_processed = 0
    with torch.no_grad():
        for inputs, labels in test_loader:
            if samples_processed >= num_samples:
                break
            
            input_img = inputs[0].unsqueeze(0).to(device)
            true_label = labels[0].item()

            # Predict with the model
            logits = model(input_img)
            probabilities = F.softmax(logits, dim=1)
            predicted_label = torch.argmax(probabilities).item()
            predicted_confidence = probabilities[0, predicted_label].item()

            # Compute Integrated Gradients attributions
            # `target` specifies the class for which to compute attributions
            # `baselines` is a reference input (e.g., all zeros, or mean image)
            # here, using zeros as baseline
            attributions_ig = ig.attribute(input_img, target=predicted_label, baselines=input_img * 0)
            
            # Convert attributions to numpy and squeeze channel dimension
            attribution_map = attributions_ig.squeeze().cpu().numpy()

            # Original image
            original_img_np = input_img.squeeze().cpu().numpy()

            # Plotting
            ax = axes[samples_processed, 0]
            ax.imshow(original_img_np, cmap='gray')
            ax.set_title(f'Original (True: {true_label})')
            ax.axis('off')

            ax = axes[samples_processed, 1]
            # Plot attribution map, often using 'RdBu' or similar cmap for positive/negative contributions
            ax.imshow(attribution_map, cmap='RdBu', vmin=-np.max(np.abs(attribution_map)), vmax=np.max(np.abs(attribution_map)))
            ax.set_title(f'Integrated Gradients (Pred: {predicted_label}, Conf: {predicted_confidence:.2f})')
            ax.axis('off')

            samples_processed += 1
    
    plt.tight_layout()
    plt.show()
    print("--- Integrated Gradients Explanation Complete ---")


# --- Section 6: SHAP Implementation (for Model-Agnostic Explanations) ---
# SHAP (SHapley Additive exPlanations) attributes a prediction to individual features.
# For deep learning models, `shap.GradientExplainer` (for differentiable models)
# or `shap.KernelExplainer` (model-agnostic, but slower) can be used.

def visualize_shap_explanations(model, test_loader, num_samples=2):
    """
    Visualizes SHAP explanations for a few test samples using GradientExplainer.
    This attributes pixel importance for a specific prediction.
    """
    print("\n--- Visualizing SHAP Explanations ---")
    model.eval()

    # Get a batch of background data for SHAP (important for explainer initialization)
    background_data = next(iter(test_loader))[0].to(device)

    # Use shap.GradientExplainer for PyTorch models (requires differentiability)
    # This explainer takes the model and a baseline (background) dataset.
    # It will compute attributions for each input sample.
    explainer = shap.GradientExplainer(model, background_data)

    samples_processed = 0
    with torch.no_grad(): # Use no_grad for getting inputs, but shap needs gradients for attribution
        # Disable no_grad if you need to pass through the model again within shap
        # For GradientExplainer, it handles the model's gradients internally.
        for inputs, labels in test_loader:
            if samples_processed >= num_samples:
                break
            
            # Select one sample and its label
            input_img = inputs[0].unsqueeze(0).to(device)
            true_label = labels[0].item()

            # Compute SHAP values for the input image
            # `labels_to_explain` can be the predicted label or a specific class to explain
            # For this demo, let's explain the predicted class
            logits = model(input_img)
            predicted_label = torch.argmax(F.softmax(logits, dim=1)).item()

            # Compute SHAP values
            # `attr` will be a list of arrays/tensors, one for each output class.
            # We want attributions for the predicted_label.
            shap_values = explainer.shap_values(input_img, ranked_outputs=predicted_label)
            # shap_values[predicted_label] should give attributions for that class
            # For multi-class, shap_values is a list of arrays (one for each class).
            # If you want to explain one class, pick that index.
            
            # `shap_values` from GradientExplainer returns a list (one per class output).
            # Each element is (batch_size, channels, height, width).
            # For our binary case, shap_values will be [attributions_for_class0, attributions_for_class1]
            
            # Select attributions for the predicted class
            if isinstance(shap_values, list): # Multi-output model
                attribution_map = shap_values[predicted_label][0].squeeze() # Squeeze batch and channel
            else: # Single output model
                attribution_map = shap_values[0].squeeze() # Squeeze batch and channel

            original_img_np = input_img.squeeze().cpu().numpy()

            # Plotting (similar to integrated gradients, showing pixel attribution)
            fig, axes = plt.subplots(1, 2, figsize=(8, 4))
            fig.suptitle(f'SHAP Explanation for Image (True: {true_label}, Pred: {predicted_label})', fontsize=12)

            ax = axes[0]
            ax.imshow(original_img_np, cmap='gray')
            ax.set_title('Original Image')
            ax.axis('off')

            ax = axes[1]
            im = ax.imshow(attribution_map, cmap='RdBu', 
                            vmin=-np.max(np.abs(attribution_map)), vmax=np.max(np.abs(attribution_map)))
            ax.set_title('SHAP Attributions')
            ax.axis('off')
            plt.colorbar(im, ax=ax, orientation='vertical', fraction=0.046, pad=0.04)

            plt.tight_layout()
            plt.show()

            samples_processed += 1
    
    print("--- SHAP Explanation Complete ---")


# --- Main Execution Flow ---
if __name__ == '__main__':
    # Step 1: Model Training (already run above, model is ready)

    # Step 2: Grad-CAM Visualization
    # Explains what parts of the image the CNN focused on.
    visualize_grad_cam(model, test_loader, num_samples=3)

    # Step 3: Integrated Gradients Visualization
    # Explains pixel importance for the classification.
    visualize_integrated_gradients(model, test_loader, num_samples=3)

    # Step 4: SHAP Visualization
    # Provides model-agnostic pixel importance (for differentiable models).
    visualize_shap_explanations(model, test_loader, num_samples=2)

    print("\nAll XAI demonstrations completed for the dummy CNN model.")

